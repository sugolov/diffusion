{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c0ba89-eeea-4bdc-9487-936fab6c259f",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 diffusion model\n",
    "\n",
    "- https://huggingface.co/google/ddpm-cifar10-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b73480-9659-4302-b60c-addc70c943d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T20:07:05.884769408Z",
     "start_time": "2024-02-27T20:06:59.854683370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": "model_index.json:   0%|          | 0.00/180 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1c28d7ac56f44d583108af0e716c257"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5a9bf9b9d474a4f8cdb42b0d6219cda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3dbeb482d074dbbaf170096b6faf37a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "scheduler_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0280ce16a17a48df88a6a14b8c677aa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "diffusion_pytorch_model.safetensors:   0%|          | 0.00/143M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65e2709d087940fb97e5927daf40ac3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8963609e6e340b2aeb1b2f45a5de59b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from checkpoint file for '/home/alex/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80/diffusion_pytorch_model.safetensors' at '/home/alex/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80/diffusion_pytorch_model.safetensors'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:108\u001B[0m, in \u001B[0;36mload_state_dict\u001B[0;34m(checkpoint_file, variant)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file_extension \u001B[38;5;241m==\u001B[39m SAFETENSORS_FILE_EXTENSION:\n\u001B[0;32m--> 108\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msafetensors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mload_file(checkpoint_file, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'safetensors' has no attribute 'torch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:114\u001B[0m, in \u001B[0;36mload_state_dict\u001B[0;34m(checkpoint_file, variant)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(checkpoint_file) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    115\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[1;32m    116\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou seem to have cloned a repository without having git-lfs installed. Please install \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    117\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgit-lfs and run `git lfs install` followed by `git lfs pull` in the folder \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    118\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou cloned.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    119\u001B[0m         )\n",
      "File \u001B[0;32m<frozen codecs>:322\u001B[0m, in \u001B[0;36mdecode\u001B[0;34m(self, input, final)\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0x88 in position 1: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoogle/ddpm-cifar10-32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# load model and scheduler\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m ddpm \u001B[38;5;241m=\u001B[39m \u001B[43mDDPMPipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# run pipeline in inference (sample random noise and denoise)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m image \u001B[38;5;241m=\u001B[39m ddpm()\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1286\u001B[0m, in \u001B[0;36mDiffusionPipeline.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m   1283\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m passed_class_obj[name]\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1285\u001B[0m     \u001B[38;5;66;03m# load sub model\u001B[39;00m\n\u001B[0;32m-> 1286\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_sub_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimportable_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimportable_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpipelines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipelines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1291\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_pipeline_module\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_pipeline_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1292\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpipeline_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipeline_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1293\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1294\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprovider\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprovider\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1295\u001B[0m \u001B[43m        \u001B[49m\u001B[43msess_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msess_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_variants\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_variants\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvariant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcached_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcached_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1307\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m   1309\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m as \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` subfolder of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1310\u001B[0m     )\n\u001B[1;32m   1312\u001B[0m init_kwargs[name] \u001B[38;5;241m=\u001B[39m loaded_sub_model  \u001B[38;5;66;03m# UNet(...), # DiffusionSchedule(...)\u001B[39;00m\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:534\u001B[0m, in \u001B[0;36mload_sub_model\u001B[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, revision)\u001B[0m\n\u001B[1;32m    531\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m load_method(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(cached_folder, name), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloading_kwargs)\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;66;03m# else load from the root directory\u001B[39;00m\n\u001B[0;32m--> 534\u001B[0m     loaded_sub_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcached_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mloading_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_sub_model\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:740\u001B[0m, in \u001B[0;36mModelMixin.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    738\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_config(config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwargs)\n\u001B[0;32m--> 740\u001B[0m     state_dict \u001B[38;5;241m=\u001B[39m \u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariant\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    741\u001B[0m     model\u001B[38;5;241m.\u001B[39m_convert_deprecated_attention_blocks(state_dict)\n\u001B[1;32m    743\u001B[0m     model, missing_keys, unexpected_keys, mismatched_keys, error_msgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_load_pretrained_model(\n\u001B[1;32m    744\u001B[0m         model,\n\u001B[1;32m    745\u001B[0m         state_dict,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    748\u001B[0m         ignore_mismatched_sizes\u001B[38;5;241m=\u001B[39mignore_mismatched_sizes,\n\u001B[1;32m    749\u001B[0m     )\n",
      "File \u001B[0;32m~/Python/diffusion/venv/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:126\u001B[0m, in \u001B[0;36mload_state_dict\u001B[0;34m(checkpoint_file, variant)\u001B[0m\n\u001B[1;32m    121\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    122\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to locate the file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheckpoint_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m which is necessary to load this pretrained \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    123\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel. Make sure you have saved the model properly.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mUnicodeDecodeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[1;32m    127\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to load weights from checkpoint file for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheckpoint_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mat \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheckpoint_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    130\u001B[0m     )\n",
      "\u001B[0;31mOSError\u001B[0m: Unable to load weights from checkpoint file for '/home/alex/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80/diffusion_pytorch_model.safetensors' at '/home/alex/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80/diffusion_pytorch_model.safetensors'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
     ]
    }
   ],
   "source": [
    "from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\n",
    "\n",
    "model_id = \"google/ddpm-cifar10-32\"\n",
    "\n",
    "# load model and scheduler\n",
    "ddpm = DDPMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\n",
    "\n",
    "# run pipeline in inference (sample random noise and denoise)\n",
    "image = ddpm().images[0]\n",
    "\n",
    "# save image\n",
    "image.save(\"ddpm_generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a586a3fdb3f568c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
